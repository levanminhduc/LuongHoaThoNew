import { NextRequest, NextResponse } from "next/server"
import { createServiceClient } from "@/utils/supabase/server"
import * as XLSX from "xlsx"
import jwt from "jsonwebtoken"
import { ApiErrorHandler, type ApiError, type ApiResponse } from "@/lib/api-error-handler"
import { DEFAULT_FIELD_HEADERS } from "@/lib/utils/header-mapping"
import { getVietnamTimestamp } from "@/lib/utils/vietnam-timezone"

const JWT_SECRET = process.env.JWT_SECRET || "your-secret-key-change-this-in-production"

// Verify admin token
function verifyAdminToken(request: NextRequest) {
  const authHeader = request.headers.get("authorization")
  if (!authHeader || !authHeader.startsWith("Bearer ")) {
    return null
  }

  const token = authHeader.substring(7)
  try {
    const decoded = jwt.verify(token, JWT_SECRET) as any
    return decoded.role === "admin" ? decoded : null
  } catch {
    return null
  }
}

// Function to load aliases from database and create comprehensive header mapping
async function createHeaderToFieldMapping(supabase: any): Promise<Record<string, string>> {
  const HEADER_TO_FIELD: Record<string, string> = {}

  // 1. Add DEFAULT_FIELD_HEADERS
  Object.entries(DEFAULT_FIELD_HEADERS).forEach(([field, header]) => {
    HEADER_TO_FIELD[header] = field
  })

  // 2. Add legacy headers
  const LEGACY_HEADER_MAPPINGS: Record<string, string> = {
    "BHXH BHTN BHYT Total": "bhxh_bhtn_bhyt_total",
    "Ti·ªÅn Khen Th∆∞·ªüng Chuy√™n C·∫ßn": "thuong_chuyen_can",
  }
  Object.assign(HEADER_TO_FIELD, LEGACY_HEADER_MAPPINGS)

  // 3. Load and add aliases from database
  try {
    const { data: aliases, error } = await supabase
      .from("column_aliases")
      .select("database_field, alias_name")
      .eq("is_active", true)

    if (!error && aliases) {
      aliases.forEach((alias: any) => {
        HEADER_TO_FIELD[alias.alias_name] = alias.database_field
      })
      console.log(`‚úÖ Loaded ${aliases.length} column aliases`)
    }
  } catch (error) {
    console.warn("‚ö†Ô∏è Could not load aliases, using defaults only:", error)
  }

  // 4. Load and add mapping configurations
  try {
    const { data: configs, error } = await supabase
      .from("mapping_configurations")
      .select(`
        configuration_field_mappings (
          database_field,
          excel_column_name
        )
      `)
      .eq("is_active", true)

    if (!error && configs) {
      configs.forEach((config: any) => {
        config.configuration_field_mappings?.forEach((mapping: any) => {
          HEADER_TO_FIELD[mapping.excel_column_name] = mapping.database_field
        })
      })
      console.log(`‚úÖ Loaded mapping configurations`)
    }
  } catch (error) {
    console.warn("‚ö†Ô∏è Could not load mapping configurations:", error)
  }

  return HEADER_TO_FIELD
}

interface ImportError {
  row: number
  employee_id?: string
  salary_month?: string
  field?: string
  error: string
  errorType: "validation" | "duplicate" | "employee_not_found" | "database" | "format"
}

interface ImportResult {
  success: boolean
  totalRecords: number
  successCount: number
  errorCount: number
  overwriteCount: number
  errors: ImportError[]
  processingTime: string
}

export async function POST(request: NextRequest) {
  const startTime = Date.now()
  const batchId = `IMPORT_${Date.now()}`

  try {
    // Verify admin authentication
    const admin = verifyAdminToken(request)
    if (!admin) {
      const error = ApiErrorHandler.createError(
        ApiErrorHandler.ErrorCodes.UNAUTHORIZED,
        ApiErrorHandler.getUserFriendlyMessage(ApiErrorHandler.ErrorCodes.UNAUTHORIZED)
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 401 })
    }

    const formData = await request.formData()
    const file = formData.get("file") as File

    if (!file) {
      const error = ApiErrorHandler.createError(
        ApiErrorHandler.ErrorCodes.VALIDATION_ERROR,
        "Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c upload"
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 400 })
    }

    // Validate file type
    const allowedTypes = [
      "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", // .xlsx
      "application/vnd.ms-excel", // .xls
    ]

    if (!allowedTypes.includes(file.type)) {
      const error = ApiErrorHandler.createError(
        ApiErrorHandler.ErrorCodes.INVALID_FILE_FORMAT,
        "File kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. Ch·ªâ ch·∫•p nh·∫≠n file .xlsx ho·∫∑c .xls"
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 400 })
    }

    // Parse Excel file
    const buffer = await file.arrayBuffer()
    const workbook = XLSX.read(buffer, { type: "buffer" })
    const sheetName = workbook.SheetNames[0]
    const worksheet = workbook.Sheets[sheetName]
    const jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1 }) as any[][]

    if (jsonData.length < 2) {
      const error = ApiErrorHandler.createError(
        ApiErrorHandler.ErrorCodes.EMPTY_FILE,
        "File kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c thi·∫øu header"
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 400 })
    }

    const headers = jsonData[0] as string[]
    const rows = jsonData.slice(1)

    // ‚úÖ Initialize Supabase client first
    const supabase = createServiceClient()

    // ‚úÖ Create comprehensive header mapping with aliases and configurations
    const HEADER_TO_FIELD = await createHeaderToFieldMapping(supabase)

    // Map headers to database fields
    const fieldMapping: Record<number, string> = {}
    const unmappedHeaders: string[] = []

    headers.forEach((header, index) => {
      const trimmedHeader = header.trim()
      const field = HEADER_TO_FIELD[trimmedHeader]
      if (field) {
        fieldMapping[index] = field
      } else {
        unmappedHeaders.push(trimmedHeader)
      }
    })

    // Debug logging for headers
    console.log("üìã Excel Headers Found:", headers)
    console.log("‚úÖ Mapped Fields:", Object.values(fieldMapping))
    console.log("‚ùå Unmapped Headers:", unmappedHeaders)
    console.log("üîç Available Mappings:", Object.keys(HEADER_TO_FIELD).slice(0, 10), "... (total:", Object.keys(HEADER_TO_FIELD).length, ")")

    // Validate required fields
    const requiredFields = ["employee_id", "salary_month"]
    const missingFields = requiredFields.filter(field =>
      !Object.values(fieldMapping).includes(field)
    )

    if (missingFields.length > 0) {
      const error = ApiErrorHandler.createError(
        ApiErrorHandler.ErrorCodes.VALIDATION_ERROR,
        `Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: ${missingFields.join(", ")}.
        Headers t√¨m th·∫•y: [${headers.join(", ")}].
        Headers kh√¥ng map ƒë∆∞·ª£c: [${unmappedHeaders.join(", ")}].
        Vui l√≤ng ki·ªÉm tra t√™n c·ªôt trong file Excel c√≥ kh·ªõp v·ªõi template kh√¥ng.`
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 400 })
    }
    const errors: ImportError[] = []
    let successCount = 0
    let overwriteCount = 0

    // Get all existing employees for validation
    const { data: employees, error: employeesError } = await supabase
      .from("employees")
      .select("employee_id")

    if (employeesError) {
      console.error("‚ùå Database error loading employees:", employeesError)
      const error = ApiErrorHandler.createDatabaseError(
        "l·∫•y danh s√°ch nh√¢n vi√™n",
        employeesError.message
      )
      return NextResponse.json(ApiErrorHandler.createErrorResponse(error), { status: 500 })
    }

    const validEmployeeIds = new Set(employees?.map(emp => emp.employee_id) || [])
    console.log("üë• Valid Employee IDs loaded:", Array.from(validEmployeeIds))

    // Process each row
    for (let i = 0; i < rows.length; i++) {
      const row = rows[i]
      const rowNumber = i + 2 // +2 because arrays are 0-indexed and we skip header

      try {
        // Map row data to database fields
        const recordData: Record<string, any> = {
          source_file: file.name,
          import_batch_id: batchId,
          import_status: "imported",
          created_at: getVietnamTimestamp(),
          updated_at: getVietnamTimestamp()
        }

        // Extract data from row with improved value processing
        Object.entries(fieldMapping).forEach(([colIndex, field]) => {
          const value = row[parseInt(colIndex)]

          // Handle required fields (employee_id, salary_month)
          if (field === "employee_id" || field === "salary_month") {
            if (value !== undefined && value !== null && String(value).trim() !== "") {
              recordData[field] = String(value).trim()
            }
          } else {
            // Handle optional numeric fields - be more permissive
            if (value !== undefined && value !== null) {
              const stringValue = String(value).trim()
              if (stringValue !== "") {
                const numValue = Number(stringValue)
                recordData[field] = isNaN(numValue) ? 0 : numValue
              } else {
                // Set default value for empty cells
                recordData[field] = 0
              }
            } else {
              // Set default value for null/undefined
              recordData[field] = 0
            }
          }
        })

        // Debug: Log mapped fields count
        const mappedFieldsCount = Object.keys(fieldMapping).length
        const recordFieldsCount = Object.keys(recordData).length - 5 // Exclude metadata fields
        console.log(`üîç Row ${rowNumber}: Mapped ${mappedFieldsCount} fields, Record has ${recordFieldsCount} data fields`)

        // Debug logging for each row (first few rows only)
        if (rowNumber <= 3) {
          console.log(`üîç Row ${rowNumber} detailed data:`, {
            employee_id: recordData.employee_id,
            salary_month: recordData.salary_month,
            sample_fields: Object.fromEntries(
              Object.entries(recordData)
                .filter(([key]) => !["source_file", "import_batch_id", "import_status", "created_at", "updated_at"].includes(key))
                .slice(0, 5)
            ),
            total_fields: Object.keys(recordData).length,
            rawRow: row.slice(0, 5)
          })
        }

        // Validate required fields
        if (!recordData.employee_id || !recordData.salary_month) {
          const error = {
            row: rowNumber,
            employee_id: recordData.employee_id,
            salary_month: recordData.salary_month,
            error: `Thi·∫øu d·ªØ li·ªáu b·∫Øt bu·ªôc - Employee ID: "${recordData.employee_id || 'EMPTY'}", Salary Month: "${recordData.salary_month || 'EMPTY'}". Ki·ªÉm tra d·ªØ li·ªáu trong file Excel.`,
            errorType: "validation" as const
          }
          console.log(`‚ùå Row ${rowNumber} validation error:`, error)
          errors.push(error)
          continue
        }

        // Validate employee exists
        if (!validEmployeeIds.has(recordData.employee_id)) {
          const error = {
            row: rowNumber,
            employee_id: recordData.employee_id,
            salary_month: recordData.salary_month,
            error: `M√£ nh√¢n vi√™n "${recordData.employee_id}" kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng.
            Valid Employee IDs: [${Array.from(validEmployeeIds).slice(0, 10).join(", ")}${validEmployeeIds.size > 10 ? "..." : ""}].
            Vui l√≤ng ki·ªÉm tra l·∫°i m√£ nh√¢n vi√™n ho·∫∑c th√™m nh√¢n vi√™n v√†o h·ªá th·ªëng tr∆∞·ªõc.`,
            errorType: "employee_not_found" as const
          }
          console.log(`‚ùå Row ${rowNumber} employee not found:`, error)
          errors.push(error)
          continue
        }

        // Validate salary month format
        const monthPattern = /^\d{4}-\d{2}$/
        if (!monthPattern.test(recordData.salary_month)) {
          errors.push({
            row: rowNumber,
            employee_id: recordData.employee_id,
            salary_month: recordData.salary_month,
            error: `Th√°ng l∆∞∆°ng "${recordData.salary_month}" kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. Ph·∫£i c√≥ ƒë·ªãnh d·∫°ng YYYY-MM (v√≠ d·ª•: 2024-01, 2024-12)`,
            errorType: "validation"
          })
          continue
        }

        // Check if record exists (for overwrite logic)
        const { data: existingRecord } = await supabase
          .from("payrolls")
          .select("id")
          .eq("employee_id", recordData.employee_id)
          .eq("salary_month", recordData.salary_month)
          .single()

        if (existingRecord) {
          // Overwrite existing record
          const { error: updateError } = await supabase
            .from("payrolls")
            .update(recordData)
            .eq("employee_id", recordData.employee_id)
            .eq("salary_month", recordData.salary_month)

          if (updateError) {
            errors.push({
              row: rowNumber,
              employee_id: recordData.employee_id,
              salary_month: recordData.salary_month,
              error: `L·ªói c·∫≠p nh·∫≠t: ${updateError.message}`,
              errorType: "database"
            })
          } else {
            overwriteCount++
            successCount++
          }
        } else {
          // Insert new record
          const { error: insertError } = await supabase
            .from("payrolls")
            .insert(recordData)

          if (insertError) {
            errors.push({
              row: rowNumber,
              employee_id: recordData.employee_id,
              salary_month: recordData.salary_month,
              error: `L·ªói th√™m m·ªõi: ${insertError.message}`,
              errorType: "database"
            })
          } else {
            successCount++
          }
        }

      } catch (error) {
        errors.push({
          row: rowNumber,
          employee_id: "UNKNOWN",
          salary_month: "UNKNOWN",
          error: error instanceof Error ? error.message : "L·ªói kh√¥ng x√°c ƒë·ªãnh",
          errorType: "format"
        })
      }
    }

    const processingTime = `${((Date.now() - startTime) / 1000).toFixed(2)}s`

    const result: ImportResult = {
      success: errors.length === 0,
      totalRecords: rows.length,
      successCount,
      errorCount: errors.length,
      overwriteCount,
      errors: errors.slice(0, 50), // Limit errors for response size
      processingTime
    }

    const message = `Import ho√†n t·∫•t: ${successCount} th√†nh c√¥ng, ${errors.length} l·ªói${overwriteCount > 0 ? `, ${overwriteCount} ghi ƒë√®` : ""}`

    if (errors.length > 0) {
      const standardizedErrors: ApiError[] = errors.slice(0, 20).map(error =>
        ApiErrorHandler.createError(
          error.errorType === "validation" ? ApiErrorHandler.ErrorCodes.VALIDATION_ERROR :
          error.errorType === "employee_not_found" ? ApiErrorHandler.ErrorCodes.EMPLOYEE_NOT_FOUND :
          error.errorType === "duplicate" ? ApiErrorHandler.ErrorCodes.DUPLICATE_RECORD :
          ApiErrorHandler.ErrorCodes.DATABASE_ERROR,
          error.error,
          `Row ${error.row}`,
          error.field,
          error.row,
          error.employee_id,
          error.salary_month
        )
      )

      // Return custom response with importBatchId for partial success
      return NextResponse.json({
        success: successCount > 0, // True if any records succeeded
        data: result,
        errors: standardizedErrors,
        message,
        metadata: {
          totalRecords: rows.length,
          successCount,
          errorCount: errors.length,
          processingTime,
          autoFixCount: 0
        },
        importBatchId: batchId // Add at top level for easy access
      })
    }

    return NextResponse.json({
      success: true,
      data: result,
      message,
      metadata: {
        totalRecords: rows.length,
        successCount,
        errorCount: errors.length,
        processingTime,
        autoFixCount: 0
      },
      importBatchId: batchId // Add at top level for easy access
    })

  } catch (error) {
    console.error("Payroll import error:", error)
    const apiError = ApiErrorHandler.fromError(error, ApiErrorHandler.ErrorCodes.INTERNAL_ERROR)
    return NextResponse.json(
      ApiErrorHandler.createErrorResponse(apiError),
      { status: 500 }
    )
  }
}
